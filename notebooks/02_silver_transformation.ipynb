{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d5d156b",
   "metadata": {},
   "source": [
    "Setup Spark & Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3645a1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, when, datediff\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"Bronze Layer Ingestion\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e496a1",
   "metadata": {},
   "source": [
    "Read data from bronze folder and save them as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bronze_path = Path(\"../delta/bronze\")\n",
    "silver_path = Path(\"../delta/silver\")\n",
    "\n",
    "customers = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_path}/olist_customers_dataset\")\n",
    "orders = spark.read.format(\"delta\").load(f\"{bronze_path}/olist_orders_dataset\")\n",
    "order_items = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_path}/olist_order_items_dataset\")\n",
    "payments = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_path}/olist_order_payments_dataset\")\n",
    "reviews = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_path}/olist_order_reviews_dataset\")\n",
    "products = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_path}/olist_products_dataset\")\n",
    "sellers = spark.read.format(\"delta\").load(\n",
    "    f\"{bronze_path}/olist_sellers_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426f847",
   "metadata": {},
   "source": [
    "Remove Duplicates & Handle Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ea2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a dimension table, so we retain only one row per customer_id\n",
    "# and remove any rows with null values in any column.\n",
    "customers_clean = customers.dropDuplicates([\"customer_id\"]).dropna()\n",
    "\n",
    "# order_id is unique in this table. We deduplicate based on order_id\n",
    "# Exclude delivery date columns when dropping rows with nulls, since order vary on status\n",
    "nullable_cols = [\"order_delivered_carrier_date\",\n",
    "                 \"order_delivered_customer_date\"]\n",
    "non_nullable_cols = [col for col in orders.columns if col not in nullable_cols]\n",
    "\n",
    "orders_clean = orders.dropDuplicates(\n",
    "    [\"order_id\"]).dropna(subset=non_nullable_cols)\n",
    "\n",
    "# This table represents order items. We remove any fully duplicated rows\n",
    "# and drop those with null values in any column.\n",
    "order_items_clean = order_items.dropDuplicates().dropna()\n",
    "\n",
    "# This table contains one or more payment records per order, acting as a fact table.\n",
    "# We deduplicate all identical rows and remove those with null values.\n",
    "payments_clean = payments.dropDuplicates().dropna()\n",
    "\n",
    "# The review_id column has duplicates where associated order_ids differ,\n",
    "# but all other columns are identical.\n",
    "# Since all the orders_id are valid, we retain all rows but deduplicate based on all columns.\n",
    "cols_to_check = [col for col in reviews.columns if col not in [\n",
    "    \"review_comment_title\", \"review_comment_message\"]]\n",
    "reviews_clean = reviews.dropDuplicates().dropna(subset=cols_to_check)\n",
    "\n",
    "# This is a dimension table, so we keep one row per product_id\n",
    "# and remove any rows with null values in any column.\n",
    "products_clean = products.dropDuplicates([\"product_id\"]).dropna()\n",
    "\n",
    "# This is a dimension table, so we keep one row per seller_id\n",
    "# and remove any rows with null values in any column.\n",
    "sellers_clean = sellers.dropDuplicates([\"seller_id\"]).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08321f",
   "metadata": {},
   "source": [
    "Join necessary datasets to create enriched tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cbde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get customers info and add them to order table\n",
    "orders_with_customer_info = orders_clean.alias(\"a\") \\\n",
    "    .join(\n",
    "        customers_clean.select(\n",
    "            \"customer_id\",\n",
    "            \"customer_zip_code_prefix\",\n",
    "            \"customer_city\",\n",
    "            \"customer_state\"\n",
    "        ).alias(\"b\"),\n",
    "        on=col(\"a.customer_id\") == col(\"b.customer_id\"),\n",
    "        how=\"left\"\n",
    ").drop(col(\"b.customer_id\"))\n",
    "\n",
    "# Join order_items with products to get product attributes\n",
    "order_items_enriched = order_items_clean.alias(\"oi\") \\\n",
    "    .join(\n",
    "        products_clean.select(\n",
    "            \"product_id\",\n",
    "            \"product_category_name\",\n",
    "            \"product_name_lenght\",\n",
    "            \"product_description_lenght\",\n",
    "            \"product_photos_qty\",\n",
    "            \"product_weight_g\",\n",
    "            \"product_length_cm\",\n",
    "            \"product_height_cm\",\n",
    "            \"product_width_cm\"\n",
    "        ).alias(\"p\"),\n",
    "        on=col(\"oi.product_id\") == col(\"p.product_id\"),\n",
    "        how=\"left\"\n",
    ").drop(col(\"p.product_id\"))\n",
    "\n",
    "# Then join with sellers to get seller attributes\n",
    "order_items_enriched = order_items_enriched.alias(\"oi\") \\\n",
    "    .join(\n",
    "        sellers_clean.select(\n",
    "            \"seller_id\",\n",
    "            \"seller_zip_code_prefix\",\n",
    "            \"seller_city\",\n",
    "            \"seller_state\"\n",
    "        ).alias(\"s\"),\n",
    "        on=col(\"oi.seller_id\") == col(\"s.seller_id\"),\n",
    "        how=\"left\"\n",
    ").drop(col(\"s.seller_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74aa09f",
   "metadata": {},
   "source": [
    "Derive calculated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be5347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add two calculated columns in this df\n",
    "order_items_enriched = order_items_enriched \\\n",
    "    .withColumn(\"total_price\", col(\"price\") + col(\"freight_value\")) \\\n",
    "    .withColumn(\"profit_margin\", col(\"price\") - col(\"freight_value\"))\n",
    "\n",
    "# Calculate the delivery time in days while excluding null order_delivered_customer_date values,\n",
    "orders_with_customer_info = orders_with_customer_info \\\n",
    "    .withColumn(\n",
    "        \"days\",\n",
    "        when(\n",
    "            col(\"order_delivered_customer_date\").isNotNull(),\n",
    "            datediff(col(\"order_delivered_customer_date\"),\n",
    "                     col(\"order_purchase_timestamp\"))\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Aggregate payment_installments from payments_clean\n",
    "payments_agg = payments_clean.groupBy(\"order_id\") \\\n",
    "    .agg(_sum(\"payment_installments\").alias(\"payment_installments\"))\n",
    "# Join it with orders_with_customer_info to bring in payment_installments\n",
    "orders_with_customer_info = orders_with_customer_info.alias(\"o\") \\\n",
    "    .join(\n",
    "        payments_agg.alias(\"p\"),\n",
    "        on=col(\"o.order_id\") == col(\"p.order_id\"),\n",
    "        how=\"left\"\n",
    ").drop(col(\"p.order_id\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782a2aa",
   "metadata": {},
   "source": [
    "Write each DataFrame as a Delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a27b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_clean.write.format(\"delta\").mode(\n",
    "    \"overwrite\").save(str(silver_path / \"customers\"))\n",
    "orders_with_customer_info.write.format(\"delta\").mode(\n",
    "    \"overwrite\").save(str(silver_path / \"orders\"))\n",
    "order_items_enriched.write.format(\"delta\").mode(\n",
    "    \"overwrite\").save(str(silver_path / \"orders_items\"))\n",
    "payments_clean.write.format(\"delta\").mode(\n",
    "    \"overwrite\").save(str(silver_path / \"payments\"))\n",
    "reviews_clean.write.format(\"delta\").mode(\n",
    "    \"overwrite\").save(str(silver_path / \"reviews\"))\n",
    "products_clean.write.format(\"delta\").mode(\n",
    "    \"overwrite\").save(str(silver_path / \"products\"))\n",
    "sellers_clean.write.format(\"delta\").mode(\n",
    "    \"overwrite\").save(str(silver_path / \"sellers\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
